{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> TRIVIATHON </span>\n",
    "\n",
    "## Team Member:\n",
    "### Adil Hamid Malla, Sumeet Singh Arora, Rahul Bhagat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement\n",
    "Searching is very important part of present internet era. Most of the search engines try to give you\n",
    "exact and only information you ask through the query. Providing additional interesting facts\n",
    "along with required information makes user search more exploratory and help in increasing the\n",
    "user engagement. The latest search engines have started giving additional information to the user\n",
    "like www.yippy.com and others.\n",
    "\n",
    "Today trivia games are quite popular and played throughout world from pubs to mobile\n",
    "applications. It has been found that more than 50 percent of web search queries are entity based\n",
    "[1,2]. Hence amplifying the search result with such facts facts would help in increasing the user\n",
    "engagement and improve dwell time. Business case studies have shown that trivia helps improve\n",
    "revenue and user engagement. A man who tweets random facts has over 18 million followers and make about 500,000 dollars in a year [19]. We have implemented web search interface for named entities, which generates the trivia for entity based on the surprise and cohesiveness. To make it more interesting we have added the game mode for our application, user can either play trivia for facts generated from wikipedia or play for questions generated from open trivia database. [20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Work\n",
    "\n",
    "Sergey Chernov et al. [3] suggested that semantic information can be extracted from Wikipedia by\n",
    "analyzing the links between categories.\n",
    "\n",
    "Prakash et al. [4] proposed the Wikipedia Trivia Miner(WTM) which is a supervised learning based\n",
    "algorithm. WTM learns linguistic and entity-based features from a labelled dataset derived from\n",
    "the IMDB trivia section.\n",
    "\n",
    "Merzbacher [5] present a (nearly) domain-independent approach to mining trivia questions from a\n",
    "database. Generated questions are ranked and are more “interesting” if they have a modest\n",
    "number of solutions and may reasonably be solved (but are not too easy).\n",
    "\n",
    "The Google search engine has also came up with the trivia facts if you run the query fun facts or trivia.\n",
    "\n",
    "<img src=\"images/google.png\"  width=\"800\" height=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plan & Methodology\n",
    "\n",
    "As we know that the trivia associated with an entity is always centered around the rare and typical knowledge. So we can say that the trivia facts have a surprise element associated with it, which represents the trivia-worthiness of the fact. Since we are dealing with the wikipedia data, we know that the facts are mostly the categories of the article. Now to calculate the trivia-worthiness of the category, we can simply choose the category which has very less number of articles => that the category is rare and unique trait. But only taking the number into consideration may result in poor. Hence we can say that categories need to ranked using metrics. So we have following two metric to calculate the trivia-worthiness of the categories.\n",
    "\n",
    "As Tsurel et. al [6] described in their work, for calculating the trivia facts, we need to calulate the surprise factor related to each fact. To do so, we need a metric which measures how unlikely it is for the category to belong to desired entity/article. As we know that the category is the collection of articles, for example Categroy:1992 births, enlists all the people born in 1992. To measure the surprise factor for this category we will calculate the similarity of the other articles in the category to our desired article. Then surpise factor would inverse of normalized sum of similarities. Higher the surprise factor, more likely it is for category to be of trivia worthy for given entity. For example Barack Obama have won the grammy award would have high suprise factor, this is because other grammy winners would be singers not politcians, hence would less similar to Barack Obama and utlimately the surprise factor would be high.      \n",
    " \n",
    "The second metric is the calculation of the cohesiveness of the category, which is defined as the average similarity between the articles of the category. Cohesiveness describes the elusiveness of the facts. Now, we need a score which combines the two metric values for a category. Thus, the score metric is the multiplication of the cohesiveness of the category multpilied with that of surprise factor of the category.\n",
    "\n",
    "We are calculating the article to article similarity based on the top k tf-idf values of the article texts. After getting the top k tf-idf values from two articles, we get the simliarity as the avergae similiarity of top k words/tokens using the **word2vec** similairity funtion. We have used the **gensim** library to do the same.\n",
    "\n",
    "For calculating the tf-idf values, we have used a pre calulated idf values from a corpus  of 10,000 articles from Wikipedia as used in Tsurel et. al[6]. To calculate the word similarity we are using the **Word2Vec**. We have used a pre-trained model, which was trained on a **Google News** corpus of about 100 billion tokens using a neural network to produce a 300-dimensional vector space of word embeddings. Word similarity is in the range [-1,1], where higher values indicate stronger similarity. Interestingly, word2vec is known to capture semantic similarities[16, 17].\n",
    "\n",
    "Following graph shows that Bracak Obama has higher similarity with other democratic politicians as compared to grammy award winner. It means that Grammy Award winner category has high surprise because other grammy award winnners are musician and barack obama is poiltician and hence would have lower average similarity.\n",
    "\n",
    "<img src=\"images/graph2.png\"  width=\"900\" height=\"700\">\n",
    "\n",
    "Following graph shows cohesivness vs surprise for varoius categories belonging to Barack Obama. As we can see again garmmy award winner cayegory has both high cohesivesness and surprise as compared not so intersting category of Washington DC Democrats\n",
    "\n",
    "<img src=\"images/graph1.png\"  width=\"900\" height=\"700\">\n",
    "\n",
    "\n",
    "Code for graph generation is presented in graph code section fo report, which we will talk about shortly.\n",
    "\n",
    "Our application can be run from the terminal for online fetching of trivia facts for the entities given in topEntityList.txt. We have also made web application which can be run on the offline cached entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Architecture\n",
    "\n",
    "We three modules for our project. They are namely as follow:\n",
    "\n",
    "### WikiParser:\n",
    "This module uses pywikibot[18] to get the data for the wikipedia entities and categories realted to it. We have used wiki2plain[7, 21] interface for converting the wiki data into raw text format.\n",
    "\n",
    "### Wiki Trivia Metric Calculator:\n",
    "This module calculates the metrics such as top K TF-IDF and entity-entity similarity values for the wikipedia entities.\n",
    "\n",
    "### Algorithm\n",
    "This is the brain module of the project that gets data using wiki parser or from cached data and then computes the ranked trivia worthy facts about the desired entity.\n",
    "\n",
    "Following diagram is the overall archtitecture for our backend. We have also web interface whic we have discussed in later part of the report.\n",
    "\n",
    "<img src=\"images/arch.png\"  width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scrapping Using Pywikibot and Wikipedia Libraries\n",
    "\n",
    "We have used the pywikibot[18] and wikipedia libraries for scrapping the data from the wikipedia. \n",
    "\n",
    "Once we get the input entity from the user for which we have to calculate the Trivia facts. For the first case we will check whether the entity exists in the wikipedia or not. Sometimes it might happen that the user typed wrong spellings or half name, so we use the wikipedia search api for getting the best and correct entity name that is an article in the wikipedia here.\n",
    "\n",
    "Once we got the article entity here, we will proceed with the fetching the article text using the pywikibot api. We also get the categories that entity belong to. \n",
    "\n",
    "The next step involes the preprocessing of the retrieved data from the wikipedia.\n",
    "First of all we need to remove the html tags and get the plain text from it. We have used Wiki2Plain[7, 21] code for removing the html tags, images, punctuations and also unwiki the text, as it contains the text in some format like sections and subsection. \n",
    "The second step of preprocessing is lowercase all the text so that we have uniform cases. The third step is to remove the stop words. we have used the nltk library to remove the stop words. And the final preprocessing step is to do stemming using Porter Stemmer of the words and get the tokens for each article. This processing \n",
    "\n",
    "To enhance the computation of our algorithm we have used the cache at different levels. We have cached the stemming results. Moreover to reduce the api calls to fetch the data from wikipedia everytime we need the said article, we cache the top k tokens of the said entity/article in a file using the name of entity, so that we can directly fetch the token if it already has been processed. This helped us in saving alot of computation and api calls to wikipedia which is throttled. Also we are storing the final ranked trivia facts, for supporting the offline ranked retrieval of trivia facts.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Configuration for pywikibot\n",
    "family = 'wikipedia'\n",
    "mylang = 'en'\n",
    "usernames['wikipedia']['en'] = u'ExampleBot'\n",
    "\n",
    "# for more refer here : https://www.mediawiki.org/wiki/Manual:Pywikibot/user-config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wiki Parser Class\n",
    "import pywikibot\n",
    "import wiki2plain\n",
    "import re\n",
    "import random\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class WikiParser:\n",
    "    def __init__(self):\n",
    "        print(\"Making the Instance of Wiki parser.\")\n",
    "        self.site = pywikibot.Site('en', 'wikipedia')\n",
    "        self.cache_stem = {}\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.k = 50 # max number of the entities to be returned for any categories. \n",
    "                    # It was found in paper setting this value to 50 gives optimal results.\n",
    "\n",
    "    # This function token map for the entity searched\n",
    "    # it processes the data to clean it.\n",
    "    def getEntityTokens(self, wiki_entity):\n",
    "        site = pywikibot.Site('en', 'wikipedia')\n",
    "        page = pywikibot.Page(site, wiki_entity)  #here we just crawl for the new entry\n",
    "        text = page.text\n",
    "        wiki2plain_instance = wiki2plain.Wiki2Plain(text)  #make the text to plain text\n",
    "        text = wiki2plain_instance.text\n",
    "        text = text.lower()  #convert all the text to lower case. Case folding\n",
    "        current_tokens = filter(None, re.split('\\W+', text))  #get the tokens now\n",
    "        current_tokens = [word for word in current_tokens if not word in self.stop_words]\n",
    "        token_freq_map = {}\n",
    "        for token in current_tokens:\n",
    "            token = self.cacheInStem(token)\n",
    "            if token not in token_freq_map:\n",
    "                token_freq_map[token] = 1.0\n",
    "            else:\n",
    "                token_freq_map[token] += 1.0\n",
    "        return token_freq_map\n",
    "\n",
    "    # get all non hidden categories for the entity\n",
    "    def getCategoryForEntity(self, wiki_entity):\n",
    "        site = pywikibot.Site('en', 'wikipedia')\n",
    "        page = pywikibot.Page(site, wiki_entity)\n",
    "        cat_values = page.categories()\n",
    "        cat_list = list(cat_values)\n",
    "        cat_names = []\n",
    "        for cat in cat_list:\n",
    "            if not cat.isHiddenCategory():\n",
    "                cat_names.append(cat.title())\n",
    "        return cat_names\n",
    "\n",
    "\n",
    "    # get k randomly sampled entities for the given category\n",
    "    def getEntityforCategory(self, category):\n",
    "        site = pywikibot.Site('en', 'wikipedia')\n",
    "        catdata = pywikibot.Category(site, title=category)\n",
    "        entities = catdata.articles()\n",
    "        return self.getRefinedEntity(entities)\n",
    "\n",
    "    # Cache for stemmed word. Same as we did in Homework 1\n",
    "    def cacheInStem(self, token):\n",
    "        if token not in self.cache_stem:\n",
    "            self.cache_stem[token] = self.stemmer.stem(token)\n",
    "        return self.cache_stem[token]\n",
    "\n",
    "    def getRefinedEntity(self, entities):\n",
    "        refinedEntity = []\n",
    "        list_entities = list(entities)\n",
    "        if len(list_entities) <= self.k:\n",
    "            for entity in entities:\n",
    "                refinedEntity.append(entity.title())\n",
    "            return refinedEntity\n",
    "        else:\n",
    "            range_entity = range(0, len(list_entities))\n",
    "            list_sample = random.sample(range_entity, self.k)\n",
    "            for i in range(0, self.k):\n",
    "                refinedEntity.append(list_entities[list_sample[i]].title())\n",
    "            return refinedEntity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wiki2PlainText\n",
    "\n",
    "# from http://stackoverflow.com/questions/4460921/extract-the-first-paragraph-from-a-wikipedia-article-python\n",
    "# refer [7,21]\n",
    "import re\n",
    "# for converting wiki text to raw text\n",
    "class Wiki2Plain:\n",
    "    def __init__(self, wiki):\n",
    "        self.wiki = wiki\n",
    "\n",
    "        self.text = wiki\n",
    "        self.text = self.unhtml(self.text)\n",
    "        self.text = self.unwiki(self.text)\n",
    "        self.text = self.punctuate(self.text)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.text\n",
    "\n",
    "    def unwiki(self, wiki):\n",
    "        \"\"\"\n",
    "        Remove wiki markup from the text.\n",
    "        \"\"\"\n",
    "        wiki = re.sub(r'(?i)\\{\\{IPA(\\-[^\\|\\{\\}]+)*?\\|([^\\|\\{\\}]+)(\\|[^\\{\\}]+)*?\\}\\}', lambda m: m.group(2), wiki)\n",
    "        wiki = re.sub(r'(?i)\\{\\{Lang(\\-[^\\|\\{\\}]+)*?\\|([^\\|\\{\\}]+)(\\|[^\\{\\}]+)*?\\}\\}', lambda m: m.group(2), wiki)\n",
    "        wiki = re.sub(r'\\{\\{[^\\{\\}]+\\}\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?m)\\{\\{[^\\{\\}]+\\}\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?m)\\{\\|[^\\{\\}]*?\\|\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[Category:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[Image:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[File:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'\\[\\[[^\\[\\]]*?\\|([^\\[\\]]*?)\\]\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r'\\[\\[([^\\[\\]]+?)\\]\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r'\\[\\[([^\\[\\]]+?)\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)File:[^\\[\\]]*?', '', wiki)\n",
    "        wiki = re.sub(r'\\[[^\\[\\]]*? ([^\\[\\]]*?)\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r\"''+\", '', wiki)\n",
    "        wiki = re.sub(r'(?m)^\\*$', '', wiki)\n",
    "\n",
    "        return wiki\n",
    "\n",
    "    def unhtml(self, html):\n",
    "        \"\"\"\n",
    "        Remove HTML from the text.\n",
    "        \"\"\"\n",
    "        html = re.sub(r'(?i)&nbsp;', ' ', html)\n",
    "        html = re.sub(r'(?i)<br[ \\\\]*?>', '\\n', html)\n",
    "        html = re.sub(r'(?m)<!--.*?--\\s*>', '', html)\n",
    "        html = re.sub(r'(?i)<ref[^>]*>[^>]*<\\/ ?ref>', '', html)\n",
    "        html = re.sub(r'(?m)<.*?>', '', html)\n",
    "        html = re.sub(r'(?i)&amp;', '&', html)\n",
    "\n",
    "        return html\n",
    "\n",
    "    def punctuate(self, text):\n",
    "        \"\"\"\n",
    "        Convert every text part into well-formed one-space\n",
    "        separate paragraph.\n",
    "        \"\"\"\n",
    "        text = re.sub(r'\\r\\n|\\n|\\r', '\\n', text)\n",
    "        text = re.sub(r'\\n\\n+', '\\n\\n', text)\n",
    "\n",
    "        parts = text.split('\\n\\n')\n",
    "        partsParsed = []\n",
    "\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "\n",
    "            if len(part) == 0:\n",
    "                continue\n",
    "\n",
    "            partsParsed.append(part)\n",
    "\n",
    "        return '\\n\\n'.join(partsParsed)\n",
    "\n",
    "    def image(self):\n",
    "        \"\"\"\n",
    "        Retrieve the first image in the document.\n",
    "        \"\"\"\n",
    "        # match = re.search(r'(?i)\\|?\\s*(image|img|image_flag)\\s*=\\s*(<!--.*-->)?\\s*([^\\\\/:*?<>\"|%]+\\.[^\\\\/:*?<>\"|%]{3,4})', self.wiki)\n",
    "        match = re.search(r'(?i)([^\\\\/:*?<>\"|% =]+)\\.(gif|jpg|jpeg|png|bmp)', self.wiki)\n",
    "\n",
    "        if match:\n",
    "            return '%s.%s' % match.groups()\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivia Metric Calculator\n",
    "\n",
    "This class is dedicated the the extraction of metrics such entity similarity and topk TF-IDF terms for the entity whic are then used in the algorithm to claculate the surprise and cohesivesness as given in Tsurel et. al[6].\n",
    "\n",
    "The trivia scores are then obtained using the multiplication of the two metric scores obtained. We only take ten top results to be shown on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wiki-Trivia Metric Calculator\n",
    "# Since by default the encoding scheme is based on the operating system, we will enforce the encoding scheme to be utf-8\n",
    "\n",
    "# for IDF calcualtion we have used corpus of 10,000 articles from Wikipedia as used in Tsurel et. al[6]. \n",
    "# file can be found at https://github.com/DMTsurel/FunFacts/blob/master/plainIdfIndex.txt\n",
    "import sys\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "import gensim\n",
    "import heapq\n",
    "import math\n",
    "import Util as util\n",
    "import pdb\n",
    "\n",
    "class WikiTriviaMetricCalculator:\n",
    "    def __init__(self):\n",
    "        print \"Inside the Initialization of the class: WikiTriviaExtractor\"\n",
    "        self.genism_model_filename = \"GoogleNews-vectors-negative300.bin\"\n",
    "        self.model = gensim.models.KeyedVectors.load_word2vec_format(self.genism_model_filename, binary=True)\n",
    "        self.global_idf = util.getglobalfreqdict(\"plainIdfIndex.txt\")\n",
    "        self.k_val = 10 # the k value for tf-idf\n",
    "        self.doc_size = 10000.0  #document size for the idf\n",
    "        self.rare_term_freq = 10  #used for ignoring rarely occuring terms.\n",
    "        print \"Initialization Done\"\n",
    "\n",
    "    def GetModel(self):\n",
    "        if self.model:\n",
    "            return\n",
    "        print 'Generating the Model'\n",
    "        self.model = gensim.models.KeyedVectors.load_word2vec_format(self.genism_model_filename, binary=True)\n",
    "        print 'Model Generated'\n",
    "\n",
    "    # Get the top k tf idf tokens from the token freq map\n",
    "    # we are using the default frequency of 1.5 for tokens not corpora of 10,000 docs, same as used here : https://github.com/DMTsurel/FunFacts/blob/master/similarityWord2Vec.py\n",
    "    # however we are suing weighted term frequncy , rather than raw term frequcny used byt authors, which can be quite large\n",
    "    def getTopKTFIDFforEntity(self, token_frequency):\n",
    "        entity_result = {}\n",
    "        for token in token_frequency:\n",
    "            if token not in self.model.vocab:\n",
    "                continue\n",
    "            tf = 1.0 + math.log10(token_frequency[token])\n",
    "            global_freq = self.global_idf[token] if token in self.global_idf else 1.5 # we are using the same value used by authors\n",
    "            \n",
    "            if global_freq < self.rare_term_freq: #ignoring very rare terms\n",
    "                continue\n",
    "            entity_result[token] = tf * math.log10(self.doc_size/float(global_freq))\n",
    "        return heapq.nlargest(self.k_val, entity_result, key=entity_result.get)\n",
    "\n",
    "\n",
    "\n",
    "    def getEntitySimilarity(self,entity1, entity2):\n",
    "        sim1 = self.getEntitySimilarityHelper(entity1, entity2)\n",
    "        sim2 = self.getEntitySimilarityHelper(entity2, entity1)\n",
    "        return ((sim1 + sim2) / 2.0)\n",
    "    \n",
    "    # similarity base upon equation 3.1 from Tsurel et. al[6]\n",
    "    def getEntitySimilarityHelper(self, entity1, entity2):\n",
    "        sim = 0.0\n",
    "        if (len(entity1) < self.k_val or len(entity2) < self.k_val):\n",
    "            return 0.0\n",
    "        for i in range(0, self.k_val):\n",
    "            current_max = self.model.similarity(entity1[i], entity2[0])\n",
    "            for j in range(1, self.k_val):\n",
    "                current_val = self.model.similarity(entity1[i], entity2[j])\n",
    "                if current_val > current_max:\n",
    "                    current_max = current_val\n",
    "            sim += (self.k_val - i) * (current_max)\n",
    "        sim = sim / ((self.k_val+1.0) * (float(self.k_val)))\n",
    "        sim = sim * 2.0\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm Wrapper\n",
    "\n",
    "# this is the brain of our application. It calculates the ranked trivia\n",
    "# It is also responsible for cahching of the data\n",
    "\n",
    "import wiki_parser\n",
    "import wiki_trivia_metric_calculator\n",
    "import Util as util\n",
    "import pdb\n",
    "import os\n",
    "import operator\n",
    "\n",
    "#globals\n",
    "category_entity_cache_dir = \"catentcache/\"\n",
    "output_cache_dir = \"outputCache/\"\n",
    "surprise_weight = 1.1\n",
    "\n",
    "wiki_parser_instance = None\n",
    "wiki_trivia_metric_calculator_instance = None\n",
    "\n",
    "# entry point called by the driver.\n",
    "def triviaAlgorithm(search_entity, wiki_parser_instance, wiki_trivia_metric_calculator_instance):\n",
    "    entity = util.searchWiki(search_entity)\n",
    "    if not entity:\n",
    "        return\n",
    "    print \"Entity Found: \" + entity\n",
    "    # Check for the Output Cache first Off line mode\n",
    "    full_path = output_cache_dir + entity + \".txt\"\n",
    "    if not os.path.exists(output_cache_dir):\n",
    "        os.makedirs(output_cache_dir)\n",
    "\n",
    "    answer_mat = {}\n",
    "    if os.path.isfile(full_path):\n",
    "        open_output_file = open(full_path, \"r\")\n",
    "        for line in open_output_file:\n",
    "            trivia, score = line.split(\":\")\n",
    "            answer_mat[trivia] = score\n",
    "        open_output_file.close()\n",
    "        answer_mat = sorted(answer_mat.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return answer_mat\n",
    "\n",
    "\n",
    "    # If the cache doesn't exist- Make the new one for the said entity\n",
    "    entity_cats = wiki_parser_instance.getCategoryForEntity(entity)\n",
    "    if not entity_cats:\n",
    "        return\n",
    "    if not os.path.exists(category_entity_cache_dir):\n",
    "        os.makedirs(category_entity_cache_dir)\n",
    "    for entity_cat in entity_cats:\n",
    "        surprise_fact = surprise(entity, entity_cat, wiki_parser_instance, wiki_trivia_metric_calculator_instance)\n",
    "        if surprise_fact:\n",
    "            answer_mat[entity_cat.split(\":\")[1]] = surprise_fact\n",
    "            cohes_score = cohesivness(entity_cat.split(\":\")[1], wiki_trivia_metric_calculator_instance)\n",
    "            if cohes_score:\n",
    "                answer_mat[entity_cat.split(\":\")[1]] *= cohes_score\n",
    "            else:\n",
    "                answer_mat[entity_cat.split(\":\")[1]] = 0.0\n",
    "            print \"<------------- ----------------->\"\n",
    "            print \"Overall score for cat \", entity_cat, \" is \", answer_mat[entity_cat.split(\":\")[1]]\n",
    "            print \"Ending     <------------- ----------------->\"\n",
    "    answer_mat = sorted(answer_mat.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    target = open(full_path, \"w\")\n",
    "    for key in answer_mat:\n",
    "        target.write(key[0] + \":\" + repr(key[1]))\n",
    "        target.write(\"\\n\")\n",
    "    target.close()\n",
    "    return answer_mat\n",
    "\n",
    "# gives how surprising is the category for the given entity.\n",
    "def surprise(entity_input, entity_cat, wiki_parser_instance, wiki_trivia_metric_calculator_instance):\n",
    "    sum = 0.0\n",
    "    count = 0.0\n",
    "    entity_input_tokens = wiki_parser_instance.getEntityTokens(entity_input)\n",
    "    entity_input_top = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(entity_input_tokens)\n",
    "    ent_cat_path = entity_cat.split(\":\")[1]\n",
    "    path = category_entity_cache_dir + cleanifyPath(ent_cat_path) + \"/\"\n",
    "    if os.path.exists(path):\n",
    "        print \"Reading from file \"\n",
    "        outer_list = []\n",
    "        for(root, dirs, files) in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    inner_list = []\n",
    "                    current_file = open(os.path.join(root, file), \"r\")\n",
    "                    for line in current_file:\n",
    "                        line = line.replace('\\n', '')\n",
    "                        inner_list.append(line)\n",
    "                    outer_list.append(inner_list)\n",
    "        size_new = len(outer_list)\n",
    "        for i in range(0, size_new):\n",
    "            sum += wiki_trivia_metric_calculator_instance.getEntitySimilarity(entity_input_top, outer_list[i])\n",
    "            count += 1.0\n",
    "        answer = sum / count\n",
    "        print \"surprise for \", entity_cat, \" is \", (1.0 / answer)\n",
    "        return (1.0 / answer)\n",
    "\n",
    "    new_entities = wiki_parser_instance.getEntityforCategory(entity_cat)\n",
    "    if not new_entities:\n",
    "        return\n",
    "\n",
    "    for new_entity in new_entities:\n",
    "        if new_entity != entity_input:\n",
    "            new_entity_tokens = wiki_parser_instance.getEntityTokens(new_entity)\n",
    "            new_entity_tokens_top = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(new_entity_tokens)\n",
    "            new_entity_top_cache = category_entity_cache_dir + cleanifyPath(ent_cat_path) + \"/\"\n",
    "            if not os.path.exists(new_entity_top_cache):\n",
    "                os.makedirs(new_entity_top_cache)\n",
    "            cache_file_name = new_entity_top_cache + cleanifyPath(new_entity) + \".txt\"\n",
    "            target = open(cache_file_name, \"w\")\n",
    "            for top_token in new_entity_tokens_top:\n",
    "                target.write(top_token)\n",
    "                target.write(\"\\n\")\n",
    "            target.close()\n",
    "            sum += wiki_trivia_metric_calculator_instance.getEntitySimilarity(entity_input_top, new_entity_tokens_top)\n",
    "            count += 1.0\n",
    "    answer = sum / count\n",
    "    print \"surprise for \" , entity_cat, \" is \", (1.0/answer)\n",
    "    return (1.0 / answer)\n",
    "\n",
    "#calcualtes the cohesivness for category\n",
    "def cohesivness(entity_cat, wiki_trivia_metric_calculator_instance):\n",
    "    sum = 0.0\n",
    "    count = 0.0\n",
    "    #answer = sum / count\n",
    "    path = category_entity_cache_dir + cleanifyPath(entity_cat) + \"/\"\n",
    "    outer_list = []\n",
    "    for(root, dirs, files) in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                inner_list = []\n",
    "                current_file = open(os.path.join(root, file), \"r\")\n",
    "                for line in current_file:\n",
    "                    line = line.replace('\\n', '')\n",
    "                    inner_list.append(line)\n",
    "                outer_list.append(inner_list)\n",
    "    size_new = len(outer_list)\n",
    "    for i in range(0, size_new):\n",
    "        for j in range(i+1, size_new):\n",
    "                sum += wiki_trivia_metric_calculator_instance.getEntitySimilarity(outer_list[i], outer_list[j])\n",
    "                count += 1.0\n",
    "    if count == 0.0:\n",
    "        return 0.0\n",
    "    answer = sum / count\n",
    "    print \"Cohes is for cat \", entity_cat, \" is \", answer\n",
    "    return answer\n",
    "\n",
    "def cleanifyPath(path):\n",
    "    path = ''.join(e for e in path if e.isalnum())\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main calling Function Entry Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Main Algorithm Calling Function\n",
    "import algorithm_wrapper\n",
    "import wikipedia as wiki\n",
    "import pdb\n",
    "import wiki_parser\n",
    "import wiki_trivia_metric_calculator\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wiki_parser_instance = wiki_parser.WikiParser()\n",
    "    wiki_trivia_metric_calculator_instance = wiki_trivia_metric_calculator.WikiTriviaMetricCalculator()\n",
    "    print \"Init done\"\n",
    "    target = open(\"input.txt\", \"r\")\n",
    "    for line in target:\n",
    "        line = line.replace('\\n', '')\n",
    "        print algorithm_wrapper.triviaAlgorithm(line, wiki_parser_instance, wiki_trivia_metric_calculator_instance)\n",
    "    target.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Generation code:\n",
    "\n",
    "we have used matplotlib to generate the line and scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It generates the similarity graph for Barack Obama with demcorats and grammy award winners in two different plots\n",
    "def drawSimPlotFixed(wiki_parser_instance, wiki_trivia_metric_calculator_instance):\n",
    "    initial_list = [\"Jimmy Carter\", \"Bill Clinton\", \"Hillary Clinton\", \"Elizabeth Warren\", \"Joe Biden\", \"Chuck Schumer\"]\n",
    "    grammy_winners = [\"Paula Abdul\", \"50 Cent\", \"Adele\", \"Yolanda Adams\", \"Bryan Adams\", \"John Addison\"]\n",
    "    tokens = wiki_parser_instance.getEntityTokens(\"Barack Obama\")\n",
    "    topk_contenders = [5, 10, 20, 40, 50]\n",
    "    colors = [\"r\", \"g\", \"b\", \"y\", \"m\"]\n",
    "    plt.figure(2)\n",
    "    size_new = len(topk_contenders)\n",
    "    for i in range(0, size_new):\n",
    "        wiki_trivia_metric_calculator_instance.k_val = topk_contenders[i]\n",
    "        topk1 = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(tokens)\n",
    "        graph_list = []\n",
    "        for val in initial_list:\n",
    "            top_current = wiki_parser_instance.getEntityTokens(val)\n",
    "            topk_current = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(top_current)\n",
    "            graph_list.append(wiki_trivia_metric_calculator_instance.getEntitySimilarity(topk1, topk_current))\n",
    "        tups = zip(*enumerate(graph_list))\n",
    "        plt.subplot(211)\n",
    "        plt.xticks(tups[0], [textwrap.fill(text, 10) for text in initial_list])\n",
    "        plt.ylim((0.0, 1.0))\n",
    "        plt.plot(tups[0], tups[1], label=str(topk_contenders[i]), color=colors[i])\n",
    "\n",
    "        graph_list_new = []\n",
    "        for val in grammy_winners:\n",
    "            top_current = wiki_parser_instance.getEntityTokens(val)\n",
    "            topk_current = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(top_current)\n",
    "            graph_list_new.append(wiki_trivia_metric_calculator_instance.getEntitySimilarity(topk1, topk_current))\n",
    "        tups_new = zip(*enumerate(graph_list_new))\n",
    "        plt.subplot(212)\n",
    "        plt.xticks(tups_new[0], [textwrap.fill(text, 10) for text in grammy_winners])\n",
    "        plt.ylim((0.0, 1.0))\n",
    "        plt.plot(tups_new[0], tups_new[1], label=str(topk_contenders[i]), color=colors[i])\n",
    "    plt.legend(title=\"Top k tokens\").draggable()\n",
    "    plt.show()\n",
    "    \n",
    "## It generates the scatter plot for barack Obama's categories for Surprise and Cohesiveness.\n",
    "def drawScatterPlot(entity):\n",
    "    x = []\n",
    "    y = []\n",
    "    anno = []\n",
    "    cats = [\"Category20thcenturyAmericanwriters\", \"CategoryAmericanNobellaureates\", \"CategoryGrammyAwardwinners\"\n",
    "            , \"CategoryWashingtonDCDemocrats\", \"CategoryPunahouSchoolalumni\", \"Category1961births\", \"CategoryUnitedStatespresidentialcandidates2012\",\n",
    "            \"CategoryPoliticiansfromChicago\"]\n",
    "    path = output_cache_graph\n",
    "    max_count = 10\n",
    "    for (root, dirs, files) in os.walk(path):\n",
    "        count = 0\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                current_file = open(os.path.join(root, file), \"r\")\n",
    "                odd = True\n",
    "                anno.append(file[:-4])\n",
    "                for line in current_file:\n",
    "                    line = line.replace('\\n', '')\n",
    "                    if odd:\n",
    "                        x.append(line)\n",
    "                    else:\n",
    "                        y.append(line)\n",
    "                    odd = False\n",
    "    plt.figure(3)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Barack Obama Cohesiveness vs Surprise\")\n",
    "    plt.xlabel(\"Surprise\")\n",
    "    plt.ylabel(\"Cohesiveness\")\n",
    "    ax.scatter(x, y)\n",
    "    for i, txt in enumerate(anno):\n",
    "        if txt in cats:\n",
    "            ax.annotate(txt, (x[i], y[i]))\n",
    "    print len(anno)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Interface\n",
    "\n",
    "Apart from making the algorithms backend engine we also developed the front end. The front-end has a trivia searching capability. We ran the algorithm for 555 most popular wiki searched persons in the recent past. This data is cached in order to decrease the turnaround time of the application/algorithm.\n",
    "\n",
    "Moreover, we also implemented the trivia gaming based on the data we have already parsed and ran through our algorithm. We randomly select five trivia True or False questions based on the trivia obtained for each entity/person.\n",
    "\n",
    "\n",
    "<img src=\"images/web1.png\"  width=\"800\" height=\"600\">\n",
    "This is the homepage of Triviathon website. It gives a brief description of the project and provides with useful links related to the project like github (source code), jupyter notebook viewer, youtube video demo and a link to trivia based game. The search bar below the header is where one can search for trivia facts related to an entity.\n",
    "\n",
    "<img src=\"images/web2.png\"  width=\"800\" height=\"600\">\n",
    "\n",
    "\n",
    "<img src=\"images/web3.png\"  width=\"800\" height=\"600\">\n",
    "<img src=\"images/web4.png\"  width=\"800\" height=\"600\">\n",
    "<img src=\"images/web5.png\"  width=\"800\" height=\"600\">\n",
    "<img src=\"images/web6.png\"  width=\"800\" height=\"600\">\n",
    "<img src=\"images/web7.png\"  width=\"800\" height=\"600\">\n",
    "<IMG>\n",
    "\n",
    "<IMG>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "We compared our results superficially with that of presented by the authors. We compared both the cohessive scores as well as the trivia facts generated by the system regarding the enetity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work\n",
    "\n",
    "Majority of the search engines enlist the results which most of the people know or plethora of the webpages reflect thus always passing the common and popular results. Moreover, the search engines results try to fulfil the information need of the user. But it might be fun and learning experience to suplement this information with trivia facts, which might surprise and entertain you. In the work presented above we provided a metric to calculate the trivia-worthiness of the facts obtained from the wikipedia. Since the evaluation part of the work couldn't be performed given the timelines and the fact that a trivia can be subjective- meaning depending in the person. This work has many benefits,as Tsurel puts it \"while seemingly lighthearted, can lead\n",
    "to higher engagement of users searching for named entities.\n",
    "If successful, even a small impact on this type of queries can\n",
    "translate into a substantial improvement in user experience,\n",
    "and possibly transfer to other domains of human activity,\n",
    "like education.\".\n",
    "\n",
    "Furthermore, to engage the user in the trivia facts and to see how our algorithm works, we developed a game based on the trivia obtained using our algorithm. We take the top five trivia facts for each entity our system has seen till now and then develop five True or False questions. Since we know the ground truth about the entity and its corresponding trivia. We form the question based on the ground truth, we involve the False answer based question by shuffling the entity and corresponding category so that now an entity can either exist in the category or not. As we know the correct answer whether that person or entity esxists in the category we can easily evaluate the answer and give a score to the user. This helps to  enhanc the trivia knowledge related to the random person or entity.\n",
    "\n",
    "Future work can be in two directions, one taking the data from some other source. As we know that the wikipedia is crowd sourced website and the chances of a category being a fact about an entity/person is debatable. Other direction could be coming up an new metric to calculate the trivia-worthiness of the fact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Mika, Peter. \"Entity search on the web.\" Proceedings of the 22nd International Conference on\n",
    "World Wide Web. ACM, 2013.\n",
    "\n",
    "[2] Yin, Xiaoxin, and Sarthak Shah. \"Building taxonomy of web search intents for name entity queries.\"\n",
    "Proceedings of the 19th international conference on World wide web. ACM, 2010.\n",
    "\n",
    "[3] Sergey Chernov, Tereza Iofciu, Wolfgang Nejdl, and Xuan Zhou. Extracting semantics relationships\n",
    "between Wikipedia categories. SemWiki, 206, 2006.\n",
    "\n",
    "[4] Abhay Prakash, Manoj K. Chinnakotla, Dhaval Patel, and Puneet Garg. Did you know?: Mining\n",
    "interesting trivia for entities from wikipedia. In Proceedings of the 24th International Conference\n",
    "on Artificial Intelligence, IJCAI'15, pages 3164--3170. AAAI Press, 2015.\n",
    "\n",
    "[5] Matthew Merzbacher. Automatic generation of trivia questions. In International Symposium on\n",
    "Methodologies for Intelligent Systems, pages 123-130.Springer, 2002.\n",
    "\n",
    "[6] Tsurel, David, et al. \"Fun Facts: Automatic Trivia Fact Extraction from Wikipedia.\" WSDM 2017.\n",
    "\n",
    "[7] Wiki2Plain:http://stackoverflow.com/questions/4460921/extract-the-first-paragraph-from-a-wikipedia-article-python\n",
    "\n",
    "[8] https://code.tutsplus.com/series/creating-a-web-app-from-scratch-using-python-flask-and-mysql--cms-827\n",
    "\n",
    "[9] https://www.w3schools.com/html/html_responsive.asp\n",
    "\n",
    "[10] http://flask.pocoo.org/\n",
    "\n",
    "[11] http://tutorialzine.com/2015/02/freebie-7-responsive-header-templates/ (Header Template)\n",
    "\n",
    "[12] http://www.flashbynight.com/tutes/mcqquiz/ (Quiz Template)\n",
    "\n",
    "[13] http://fontawesome.io/\n",
    "\n",
    "[14] http://nbviewer.jupyter.org/ (Notebook Viewer)\n",
    "\n",
    "[15] https://github.com/singhsume123/TSSE (Carousel)\n",
    "\n",
    "[16] Marco Baroni, Georgiana Dinu, and Germ ́an Kruszewski. Don’t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of Association for Computational Linguistics (ACL), volume 1, 2014.\n",
    "\n",
    "[17] Tom Kenter and Maarten de Rijke. Short text similarity with word embeddings. In Proceedings of the 4th ACM International on Conference on 353 Information and Knowledge Management, CIKM ’15, pages 1411–1420, New York, NY, USA, 2015. ACM.\n",
    "\n",
    "[18] MediaWiki. Manual:Pywikibot — Mediawiki, The Free Wiki Engine, https://www.mediawiki.org/w/index.php?title=Manual:Pywikibot&oldid=2176177, [Online; accessed 17-July-2016].\n",
    "\n",
    "[19] This 25-year-old makes $500,000 a year tweeting random facts, http://www.cnbc.com/2016/07/16/\n",
    "25-year-old-kris-sanchez-makes-500000-a-year-from-uberfacts.html. [Online; accessed 17-July-2016]\n",
    "\n",
    "[20] https://opentdb.com/api_config.php\n",
    "\n",
    "[21] Direct link to wiki2plain: https://github.com/sbenthall/bluestocking/blob/master/bluestocking/wiki2plain.py\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
