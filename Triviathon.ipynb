{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIVIATHON\n",
    "\n",
    "## Team Member:\n",
    "### Adil Hamid Malla,Sumeet Singh Arora, Rahul Bhagat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement\n",
    "Searching is very important part of present internet era. Most of the search engines try to give you\n",
    "exact and only information you ask through the query. Providing additional interesting facts\n",
    "along with required information makes user search more exploratory and help in increasing the\n",
    "user engagement. The latest search engines have started giving additional information to the user\n",
    "like www.yippy.com and others.\n",
    "\n",
    "Today trivia games are quite popular and played throughout world from pubs to mobile\n",
    "applications. It has been found that more than 50 percent of web search queries are entity based\n",
    "[1,2]. Hence amplifying the search result with such facts facts would help in increasing the user\n",
    "engagement and improve dwell time. Business case studies have shown that trivia helps improve\n",
    "revenue and user engagement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Work\n",
    "\n",
    "Sergey Chernov et al. [3] suggested that semantic information can be extracted from Wikipedia by\n",
    "analyzing the links between categories.\n",
    "\n",
    "Prakash et al. [4] proposed the Wikipedia Trivia Miner(WTM) which is a supervised learning based\n",
    "algorithm. WTM learns linguistic and entity-based features from a labelled dataset derived from\n",
    "the IMDB trivia section.\n",
    "\n",
    "Merzbacher [5] present a (nearly) domain-independent approach to mining trivia questions from a\n",
    "database. Generated questions are ranked and are more “interesting” if they have a modest\n",
    "number of solutions and may reasonably be solved (but are not too easy).\n",
    "\n",
    "The Google search engine has also came up with the trivia facts if you run the query fun facts or trivia.\n",
    "\n",
    "<img src=\"images/google.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Plan & Methodology\n",
    "\n",
    "As we know that the trivia associated with an entity is always centered around the rare and typical knowledge. So we can say that the trivia facts have a surprise element associated with it, which represents the trivia-worthiness of the fact. Since we are dealing with the wikipedia data, we know that the facts are mostly the categories of the article. Now to calculate the trivia-worthiness of the category, we can simply choose the category which has very less number of articles- meaning that the category is rare and unique trait. But only taking the number into consideration is not good idea. So we have following two metric to calculate the trivia-worthiness of the categories.\n",
    "\n",
    "As Tsurel et. al [6] described in their work, for calculating the trivia facts, we need to calulate the surprise factor related to each fact. To do so, we need a metric which measures the surprise factor of the article. As we know that the category is the collection of articles, like 1992 birth, which enlists all the people born in 1992, so, to get the surprise element, we will calculate the similarity of the articles in the category. We also measure the similarity between the articles and the categories. Finally, the surprise factor will be represented by the inverse of average similarity, thus giving as a category which is highly different from other categories.\n",
    "\n",
    "The second metric is the calculation of the cohesiveness of the category, which is defined as the average similarity between the articles of the category. Cohesiveness describes the elusiveness of the facts. Now, we need a score which combines the two metric values for a category. Thus, the score metric is the multiplication of the cohesiveness of the category multpilied with that of surprise factor of the category.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scrapping Using Pywikibot and Wikipedia Libraries\n",
    "\n",
    "We have used the pywikibot and wikipedia libraries for scrapping the data from the wikipedia. \n",
    "\n",
    "Once we get the input entity from the user for which we have to calculate the Trivia facts. For the first case we will check whether the entity exists in the wikipedia or not. Sometimes it might happen that the user typed wrong spellings or half name, so we use the wikipedia search api for getting the best and correct entity name that is an article in the wikipedia here.\n",
    "\n",
    "Once we got the article entity here, we will proceed with the fetching the article text using the pywikibot api. We also get the categories that entity belong to. \n",
    "\n",
    "The next step involes the preprocessing of the retrieved data from the wikipedia.\n",
    "First of all we need to remove the html tags and get the plain text from it. We have used Wiki2Plain[7] code for removing the html tags, images, punctuations and also unwiki the text, as it contains the text in some format like sections and subsection. \n",
    "The second step of preprocessing is lowercase all the text so that we have uniform cases. The third step is to remove the stop words. we have used the nltk library to remove the stop words. And the final preprocessing step is to do stemming using Porter Stemmer of the words and get the tokens for each article.\n",
    "\n",
    "To enhance the computation of our algorithm we have used the cache at different levels. We have cached the stemming results. Moreover to reduce the api calls to fetch the data from wikipedia everytime we need the said article, we cache the tokens of the said entity/article in a file using the name of entity, so that we can directly fetch the token if it already has been processed. This helped us in saving alot of computation and api calls to wikipedia which is throttled.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# User Configuration for pywikibot\n",
    "family = 'wikipedia'\n",
    "mylang = 'en'\n",
    "usernames['wikipedia']['en'] = u'ExampleBot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wiki Parser Class\n",
    "import pywikibot\n",
    "import wiki2plain\n",
    "import re\n",
    "import random\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class WikiParser:\n",
    "    def __init__(self):\n",
    "        print(\"Making the Instance of Wiki parser.\")\n",
    "        self.site = pywikibot.Site('en', 'wikipedia')\n",
    "        self.cache_stem = {}\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.k = 50\n",
    "\n",
    "    def getEntityTokens(self, wiki_entity):\n",
    "        site = pywikibot.Site('en', 'wikipedia')\n",
    "        page = pywikibot.Page(site, wiki_entity)  #here we just crawl for the new entry\n",
    "        text = page.text\n",
    "        wiki2plain_instance = wiki2plain.Wiki2Plain(text)  #make the text to plain text\n",
    "        text = wiki2plain_instance.text\n",
    "        text = text.lower()  #convert all the text to lower case. Case folding\n",
    "        current_tokens = filter(None, re.split('\\W+', text))  #get the tokens now\n",
    "        current_tokens = [word for word in current_tokens if not word in self.stop_words]\n",
    "        token_freq_map = {}\n",
    "        for token in current_tokens:\n",
    "            token = self.cacheInStem(token)\n",
    "            if token not in token_freq_map:\n",
    "                token_freq_map[token] = 1.0\n",
    "            else:\n",
    "                token_freq_map[token] += 1.0\n",
    "        return token_freq_map\n",
    "\n",
    "    def getCategoryForEntity(self, wiki_entity):\n",
    "        site = pywikibot.Site('en', 'wikipedia')\n",
    "        page = pywikibot.Page(site, wiki_entity)\n",
    "        cat_values = page.categories()\n",
    "        cat_list = list(cat_values)\n",
    "        cat_names = []\n",
    "        for cat in cat_list:\n",
    "            if not cat.isHiddenCategory():\n",
    "                cat_names.append(cat.title())\n",
    "        return cat_names\n",
    "\n",
    "\n",
    "\n",
    "    def getEntityforCategory(self, category):\n",
    "        site = pywikibot.Site('en', 'wikipedia')\n",
    "        catdata = pywikibot.Category(site, title=category)\n",
    "        entities = catdata.articles()\n",
    "        return self.getRefinedEntity(entities)\n",
    "\n",
    "    def cacheInStem(self, token):\n",
    "        if token not in self.cache_stem:\n",
    "            self.cache_stem[token] = self.stemmer.stem(token)\n",
    "        return self.cache_stem[token]\n",
    "\n",
    "    def getRefinedEntity(self, entities):\n",
    "        refinedEntity = []\n",
    "        list_entities = list(entities)\n",
    "        if len(list_entities) <= self.k:\n",
    "            for entity in entities:\n",
    "                refinedEntity.append(entity.title())\n",
    "            return refinedEntity\n",
    "        else:\n",
    "            range_entity = range(0, len(list_entities))\n",
    "            list_sample = random.sample(range_entity, self.k)\n",
    "            for i in range(0, self.k):\n",
    "                refinedEntity.append(list_entities[list_sample[i]].title())\n",
    "            return refinedEntity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wiki2PlainText\n",
    "\n",
    "# from http://stackoverflow.com/questions/4460921/extract-the-first-paragraph-from-a-wikipedia-article-python\n",
    "\n",
    "import re\n",
    "\n",
    "class Wiki2Plain:\n",
    "    def __init__(self, wiki):\n",
    "        self.wiki = wiki\n",
    "\n",
    "        self.text = wiki\n",
    "        self.text = self.unhtml(self.text)\n",
    "        self.text = self.unwiki(self.text)\n",
    "        self.text = self.punctuate(self.text)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.text\n",
    "\n",
    "    def unwiki(self, wiki):\n",
    "        \"\"\"\n",
    "        Remove wiki markup from the text.\n",
    "        \"\"\"\n",
    "        wiki = re.sub(r'(?i)\\{\\{IPA(\\-[^\\|\\{\\}]+)*?\\|([^\\|\\{\\}]+)(\\|[^\\{\\}]+)*?\\}\\}', lambda m: m.group(2), wiki)\n",
    "        wiki = re.sub(r'(?i)\\{\\{Lang(\\-[^\\|\\{\\}]+)*?\\|([^\\|\\{\\}]+)(\\|[^\\{\\}]+)*?\\}\\}', lambda m: m.group(2), wiki)\n",
    "        wiki = re.sub(r'\\{\\{[^\\{\\}]+\\}\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?m)\\{\\{[^\\{\\}]+\\}\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?m)\\{\\|[^\\{\\}]*?\\|\\}', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[Category:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[Image:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)\\[\\[File:[^\\[\\]]*?\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'\\[\\[[^\\[\\]]*?\\|([^\\[\\]]*?)\\]\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r'\\[\\[([^\\[\\]]+?)\\]\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r'\\[\\[([^\\[\\]]+?)\\]\\]', '', wiki)\n",
    "        wiki = re.sub(r'(?i)File:[^\\[\\]]*?', '', wiki)\n",
    "        wiki = re.sub(r'\\[[^\\[\\]]*? ([^\\[\\]]*?)\\]', lambda m: m.group(1), wiki)\n",
    "        wiki = re.sub(r\"''+\", '', wiki)\n",
    "        wiki = re.sub(r'(?m)^\\*$', '', wiki)\n",
    "\n",
    "        return wiki\n",
    "\n",
    "    def unhtml(self, html):\n",
    "        \"\"\"\n",
    "        Remove HTML from the text.\n",
    "        \"\"\"\n",
    "        html = re.sub(r'(?i)&nbsp;', ' ', html)\n",
    "        html = re.sub(r'(?i)<br[ \\\\]*?>', '\\n', html)\n",
    "        html = re.sub(r'(?m)<!--.*?--\\s*>', '', html)\n",
    "        html = re.sub(r'(?i)<ref[^>]*>[^>]*<\\/ ?ref>', '', html)\n",
    "        html = re.sub(r'(?m)<.*?>', '', html)\n",
    "        html = re.sub(r'(?i)&amp;', '&', html)\n",
    "\n",
    "        return html\n",
    "\n",
    "    def punctuate(self, text):\n",
    "        \"\"\"\n",
    "        Convert every text part into well-formed one-space\n",
    "        separate paragraph.\n",
    "        \"\"\"\n",
    "        text = re.sub(r'\\r\\n|\\n|\\r', '\\n', text)\n",
    "        text = re.sub(r'\\n\\n+', '\\n\\n', text)\n",
    "\n",
    "        parts = text.split('\\n\\n')\n",
    "        partsParsed = []\n",
    "\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "\n",
    "            if len(part) == 0:\n",
    "                continue\n",
    "\n",
    "            partsParsed.append(part)\n",
    "\n",
    "        return '\\n\\n'.join(partsParsed)\n",
    "\n",
    "    def image(self):\n",
    "        \"\"\"\n",
    "        Retrieve the first image in the document.\n",
    "        \"\"\"\n",
    "        # match = re.search(r'(?i)\\|?\\s*(image|img|image_flag)\\s*=\\s*(<!--.*-->)?\\s*([^\\\\/:*?<>\"|%]+\\.[^\\\\/:*?<>\"|%]{3,4})', self.wiki)\n",
    "        match = re.search(r'(?i)([^\\\\/:*?<>\"|% =]+)\\.(gif|jpg|jpeg|png|bmp)', self.wiki)\n",
    "\n",
    "        if match:\n",
    "            return '%s.%s' % match.groups()\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivia Metric Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wiki-Trivia Metric Calculator\n",
    "# Since by default the encoding scheme is based on the operating system, we will enforce the encoding scheme to be utf-8\n",
    "\n",
    "import sys\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "import gensim\n",
    "import heapq\n",
    "import math\n",
    "import Util as util\n",
    "import pdb\n",
    "\n",
    "class WikiTriviaMetricCalculator:\n",
    "    def __init__(self):\n",
    "        print \"Inside the Initialization of the class: WikiTriviaExtractor\"\n",
    "        self.genism_model_filename = \"GoogleNews-vectors-negative300.bin\"\n",
    "        self.model = gensim.models.KeyedVectors.load_word2vec_format(self.genism_model_filename, binary=True)\n",
    "        self.global_idf = util.getglobalfreqdict(\"plainIdfIndex.txt\")\n",
    "        self.k_val = 10\n",
    "        self.doc_size = 10000.0  #document size for the idf\n",
    "        self.rare_term_freq = 10  #used for ignoring rarely occuring terms.\n",
    "        print \"Initialization Done\"\n",
    "\n",
    "    def GetModel(self):\n",
    "        if self.model:\n",
    "            return\n",
    "        print 'Generating the Model'\n",
    "        self.model = gensim.models.KeyedVectors.load_word2vec_format(self.genism_model_filename, binary=True)\n",
    "        print 'Model Generated'\n",
    "\n",
    "    # Get the top k tf idf tokens from the token freq map\n",
    "    def getTopKTFIDFforEntity(self, token_frequency):\n",
    "        entity_result = {}\n",
    "        for token in token_frequency:\n",
    "            if token not in self.model.vocab:\n",
    "                continue\n",
    "            tf = 1.0 + math.log10(token_frequency[token])\n",
    "            global_freq = self.global_idf[token] if token in self.global_idf else 1.5\n",
    "            if global_freq < self.rare_term_freq: #ignoring very rare terms\n",
    "                continue\n",
    "            entity_result[token] = tf * math.log10(self.doc_size/float(global_freq))\n",
    "        return heapq.nlargest(self.k_val, entity_result, key=entity_result.get)\n",
    "\n",
    "\n",
    "\n",
    "    def getEntitySimilarity(self,entity1, entity2):\n",
    "        sim1 = self.getEntitySimilarityHelper(entity1, entity2)\n",
    "        sim2 = self.getEntitySimilarityHelper(entity2, entity1)\n",
    "        return ((sim1 + sim2) / 2.0)\n",
    "\n",
    "    def getEntitySimilarityHelper(self, entity1, entity2):\n",
    "        sim = 0.0\n",
    "        if (len(entity1) < self.k_val or len(entity2) < self.k_val):\n",
    "            return 0.0\n",
    "        for i in range(0, self.k_val):\n",
    "            current_max = self.model.similarity(entity1[i], entity2[0])\n",
    "            for j in range(1, self.k_val):\n",
    "                current_val = self.model.similarity(entity1[i], entity2[j])\n",
    "                if current_val > current_max:\n",
    "                    current_max = current_val\n",
    "            sim += (self.k_val - i) * (current_max)\n",
    "        sim = sim / ((self.k_val+1.0) * (float(self.k_val)))\n",
    "        sim = sim * 2.0\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm Wrapper\n",
    "import wiki_parser\n",
    "import wiki_trivia_metric_calculator\n",
    "import Util as util\n",
    "import pdb\n",
    "import os\n",
    "import operator\n",
    "\n",
    "#globals\n",
    "category_entity_cache_dir = \"catentcache/\"\n",
    "output_cache_dir = \"outputCache/\"\n",
    "surprise_weight = 1.1\n",
    "\n",
    "wiki_parser_instance = None\n",
    "wiki_trivia_metric_calculator_instance = None\n",
    "\n",
    "\n",
    "def triviaAlgorithm(search_entity, wiki_parser_instance, wiki_trivia_metric_calculator_instance):\n",
    "    entity = util.searchWiki(search_entity)\n",
    "    if not entity:\n",
    "        return\n",
    "    print \"Entity Found: \" + entity\n",
    "    # Check for the Output Cache\n",
    "    full_path = output_cache_dir + entity + \".txt\"\n",
    "    if not os.path.exists(output_cache_dir):\n",
    "        os.makedirs(output_cache_dir)\n",
    "\n",
    "    answer_mat = {}\n",
    "    if os.path.isfile(full_path):\n",
    "        open_output_file = open(full_path, \"r\")\n",
    "        for line in open_output_file:\n",
    "            trivia, score = line.split(\":\")\n",
    "            answer_mat[trivia] = score\n",
    "        open_output_file.close()\n",
    "        answer_mat = sorted(answer_mat.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return answer_mat\n",
    "\n",
    "\n",
    "    # If the cache doesn't exist- Make the new one for the said entity\n",
    "    entity_cats = wiki_parser_instance.getCategoryForEntity(entity)\n",
    "    if not entity_cats:\n",
    "        return\n",
    "    if not os.path.exists(category_entity_cache_dir):\n",
    "        os.makedirs(category_entity_cache_dir)\n",
    "    for entity_cat in entity_cats:\n",
    "        surprise_fact = surprise(entity, entity_cat, wiki_parser_instance, wiki_trivia_metric_calculator_instance)\n",
    "        if surprise_fact:\n",
    "            answer_mat[entity_cat.split(\":\")[1]] = surprise_fact\n",
    "            cohes_score = cohesivness(entity_cat.split(\":\")[1], wiki_trivia_metric_calculator_instance)\n",
    "            if cohes_score:\n",
    "                answer_mat[entity_cat.split(\":\")[1]] *= cohes_score\n",
    "            else:\n",
    "                answer_mat[entity_cat.split(\":\")[1]] = 0.0\n",
    "            print \"<------------- ----------------->\"\n",
    "            print \"Overall score for cat \", entity_cat, \" is \", answer_mat[entity_cat.split(\":\")[1]]\n",
    "            print \"Ending     <------------- ----------------->\"\n",
    "    answer_mat = sorted(answer_mat.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    target = open(full_path, \"w\")\n",
    "    for key in answer_mat:\n",
    "        target.write(key[0] + \":\" + repr(key[1]))\n",
    "        target.write(\"\\n\")\n",
    "    target.close()\n",
    "    return answer_mat\n",
    "\n",
    "def surprise(entity_input, entity_cat, wiki_parser_instance, wiki_trivia_metric_calculator_instance):\n",
    "    sum = 0.0\n",
    "    count = 0.0\n",
    "    entity_input_tokens = wiki_parser_instance.getEntityTokens(entity_input)\n",
    "    entity_input_top = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(entity_input_tokens)\n",
    "    ent_cat_path = entity_cat.split(\":\")[1]\n",
    "    path = category_entity_cache_dir + cleanifyPath(ent_cat_path) + \"/\"\n",
    "    if os.path.exists(path):\n",
    "        print \"Reading from file \"\n",
    "        outer_list = []\n",
    "        for(root, dirs, files) in os.walk(path):\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    inner_list = []\n",
    "                    current_file = open(os.path.join(root, file), \"r\")\n",
    "                    for line in current_file:\n",
    "                        line = line.replace('\\n', '')\n",
    "                        inner_list.append(line)\n",
    "                    outer_list.append(inner_list)\n",
    "        size_new = len(outer_list)\n",
    "        for i in range(0, size_new):\n",
    "            sum += wiki_trivia_metric_calculator_instance.getEntitySimilarity(entity_input_top, outer_list[i])\n",
    "            count += 1.0\n",
    "        answer = sum / count\n",
    "        print \"surprise for \", entity_cat, \" is \", (1.0 / answer)\n",
    "        return (1.0 / answer)\n",
    "\n",
    "    new_entities = wiki_parser_instance.getEntityforCategory(entity_cat)\n",
    "    if not new_entities:\n",
    "        return\n",
    "\n",
    "    for new_entity in new_entities:\n",
    "        if new_entity != entity_input:\n",
    "            new_entity_tokens = wiki_parser_instance.getEntityTokens(new_entity)\n",
    "            new_entity_tokens_top = wiki_trivia_metric_calculator_instance.getTopKTFIDFforEntity(new_entity_tokens)\n",
    "            new_entity_top_cache = category_entity_cache_dir + cleanifyPath(ent_cat_path) + \"/\"\n",
    "            if not os.path.exists(new_entity_top_cache):\n",
    "                os.makedirs(new_entity_top_cache)\n",
    "            cache_file_name = new_entity_top_cache + cleanifyPath(new_entity) + \".txt\"\n",
    "            target = open(cache_file_name, \"w\")\n",
    "            for top_token in new_entity_tokens_top:\n",
    "                target.write(top_token)\n",
    "                target.write(\"\\n\")\n",
    "            target.close()\n",
    "            sum += wiki_trivia_metric_calculator_instance.getEntitySimilarity(entity_input_top, new_entity_tokens_top)\n",
    "            count += 1.0\n",
    "    answer = sum / count\n",
    "    print \"surprise for \" , entity_cat, \" is \", (1.0/answer)\n",
    "    return (1.0 / answer)\n",
    "\n",
    "def cohesivness(entity_cat, wiki_trivia_metric_calculator_instance):\n",
    "    sum = 0.0\n",
    "    count = 0.0\n",
    "    #answer = sum / count\n",
    "    path = category_entity_cache_dir + cleanifyPath(entity_cat) + \"/\"\n",
    "    outer_list = []\n",
    "    for(root, dirs, files) in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                inner_list = []\n",
    "                current_file = open(os.path.join(root, file), \"r\")\n",
    "                for line in current_file:\n",
    "                    line = line.replace('\\n', '')\n",
    "                    inner_list.append(line)\n",
    "                outer_list.append(inner_list)\n",
    "    size_new = len(outer_list)\n",
    "    for i in range(0, size_new):\n",
    "        for j in range(i+1, size_new):\n",
    "                sum += wiki_trivia_metric_calculator_instance.getEntitySimilarity(outer_list[i], outer_list[j])\n",
    "                count += 1.0\n",
    "    if count == 0.0:\n",
    "        return 0.0\n",
    "    answer = sum / count\n",
    "    print \"Cohes is for cat \", entity_cat, \" is \", answer\n",
    "    return answer\n",
    "\n",
    "def cleanifyPath(path):\n",
    "    path = ''.join(e for e in path if e.isalnum())\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main calling Function Entry Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: C:\\Users\\AADY\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messi\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "triviaAlgorithm() takes exactly 3 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dfee30934ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_entity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[1;32mprint\u001b[0m \u001b[0malgorithm_wrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriviaAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_entity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: triviaAlgorithm() takes exactly 3 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "# Main Algorithm Calling Function\n",
    "import algorithm_wrapper\n",
    "import wikipedia as wiki\n",
    "import pdb\n",
    "import wiki_parser\n",
    "import wiki_trivia_metric_calculator\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wiki_parser_instance = wiki_parser.WikiParser()\n",
    "    wiki_trivia_metric_calculator_instance = wiki_trivia_metric_calculator.WikiTriviaMetricCalculator()\n",
    "    print \"Init done\"\n",
    "    target = open(\"input.txt\", \"r\")\n",
    "    for line in target:\n",
    "        line = line.replace('\\n', '')\n",
    "        print algorithm_wrapper.triviaAlgorithm(line, wiki_parser_instance, wiki_trivia_metric_calculator_instance)\n",
    "    target.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work\n",
    "\n",
    "Majority of the search engines enlist the results which most of the people know or plethora of the webpages reflect thus always passing the common and popular results. Moreover, the search engines results try to fulfil the information need of the user. But it might be fun and learning experience to suplement this information with trivia facts, which might surprise and entertain you. In the work presented above we provided a metric to calculate the trivia-worthiness of the facts obtained from the wikipedia. Since the evaluation part of the work couldn't be performed given the timelines and the fact that a trivia can be subjective- meaning depending in the person. This work has many benefits,as Tsurel puts it \"while seemingly lighthearted, can lead\n",
    "to higher engagement of users searching for named entities.\n",
    "If successful, even a small impact on this type of queries can\n",
    "translate into a substantial improvement in user experience,\n",
    "and possibly transfer to other domains of human activity,\n",
    "like education.\".\n",
    "\n",
    "Furthermore, to engage the user in the trivia facts and to see how our algorithm works, we developed a game based on the trivia obtained using our algorithm. We take the top five trivia facts for each entity our system has seen till now and then develop five True or False questions. Since we know the ground truth about the entity and its corresponding trivia. We form the question based on the ground truth, we involve the False answer based question by shuffling the entity and corresponding category so that now an entity can either exist in the category or not. As we know the correct answer whether that person or entity esxists in the category we can easily evaluate the answer and give a score to the user. This helps to  enhanc the trivia knowledge related to the random person or entity.\n",
    "\n",
    "Future work can be in two directions, one taking the data from some other source. As we know that the wikipedia is crowd sourced website and the chances of a category being a fact about an entity/person is debatable. Other direction could be coming up an new metric to calculate the trivia-worthiness of the fact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Mika, Peter. \"Entity search on the web.\" Proceedings of the 22nd International Conference on\n",
    "World Wide Web. ACM, 2013.\n",
    "\n",
    "[2] Yin, Xiaoxin, and Sarthak Shah. \"Building taxonomy of web search intents for name entity queries.\"\n",
    "Proceedings of the 19th international conference on World wide web. ACM, 2010.\n",
    "\n",
    "[3] Sergey Chernov, Tereza Iofciu, Wolfgang Nejdl, and Xuan Zhou. Extracting semantics relationships\n",
    "between Wikipedia categories. SemWiki, 206, 2006.\n",
    "\n",
    "[4] Abhay Prakash, Manoj K. Chinnakotla, Dhaval Patel, and Puneet Garg. Did you know?: Mining\n",
    "interesting trivia for entities from wikipedia. In Proceedings of the 24th International Conference\n",
    "on Artificial Intelligence, IJCAI'15, pages 3164--3170. AAAI Press, 2015.\n",
    "\n",
    "[5] Matthew Merzbacher. Automatic generation of trivia questions. In International Symposium on\n",
    "Methodologies for Intelligent Systems, pages 123-130.Springer, 2002.\n",
    "\n",
    "[6] Tsurel, David, et al. \"Fun Facts: Automatic Trivia Fact Extraction from Wikipedia.\" WSDM 2017.\n",
    "\n",
    "[7] Wiki2Plain Reference\n",
    "\n",
    "[8] https://code.tutsplus.com/series/creating-a-web-app-from-scratch-using-python-flask-and-mysql--cms-827\n",
    "\n",
    "[9] https://www.w3schools.com/html/html_responsive.asp\n",
    "\n",
    "[10] http://flask.pocoo.org/\n",
    "\n",
    "[11] http://tutorialzine.com/2015/02/freebie-7-responsive-header-templates/ (Header Template)\n",
    "\n",
    "[12] http://www.flashbynight.com/tutes/mcqquiz/ (Quiz Template)\n",
    "\n",
    "[13] http://fontawesome.io/\n",
    "\n",
    "[14] http://nbviewer.jupyter.org/ (Notebook Viewer)\n",
    "\n",
    "[15] https://github.com/singhsume123/TSSE (Carousel)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
